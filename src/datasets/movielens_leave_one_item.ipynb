{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "import utils.constants as Constants\n",
    "from utils.unigramTable import UnigramTable\n",
    "\n",
    "# indicators of the colunmn name\n",
    "DEFAULT_USER_COL = Constants.DEFAULT_USER_COL\n",
    "DEFAULT_ITEM_COL = Constants.DEFAULT_ITEM_COL\n",
    "DEFAULT_ORDER_COL = Constants.DEFAULT_ORDER_COL\n",
    "DEFAULT_RATING_COL = Constants.DEFAULT_RATING_COL\n",
    "DEFAULT_LABEL_COL = Constants.DEFAULT_LABEL_COL\n",
    "DEFAULT_TIMESTAMP_COL = Constants.DEFAULT_TIMESTAMP_COL\n",
    "DEFAULT_PREDICTION_COL = Constants.DEFAULT_PREDICTION_COL\n",
    "DEFAULT_FLAG_COL = Constants.DEFAULT_FLAG_COL\n",
    "\n",
    "ml1m_dir = \"../datasets/ml-1m/raw/ratings.dat\"\n",
    "ml1m_rating = pd.read_csv(\n",
    "    ml1m_dir,\n",
    "    sep=\"::\",\n",
    "    header=None,\n",
    "    names=[\"uid\", \"mid\", \"rating\", \"timestamp\"],\n",
    "    engine=\"python\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = ml1m_rating.rename(\n",
    "    columns={\n",
    "        \"uid\": DEFAULT_USER_COL,\n",
    "        \"mid\": DEFAULT_ITEM_COL,\n",
    "        \"rating\": DEFAULT_RATING_COL,\n",
    "        \"timestamp\": DEFAULT_TIMESTAMP_COL,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_neg_sample(eval_df, negative_num, item_sampler):\n",
    "    \"\"\" \n",
    "    sampling negative sampling for evaluation.\n",
    "\n",
    "\n",
    "    Parameters:\n",
    "            eval_df: Dataframe with column naming 'user_ids', 'item_ids' and 'ratings',\n",
    "            where all the ratings is 1\n",
    "\n",
    "    Returns:\n",
    "            eval_df with column naming 'user_ids', 'item_ids' and 'ratings' appended \n",
    "            with negetive samples and the ratings is 0\n",
    "    \"\"\"\n",
    "    print(\"sampling negative items...\")\n",
    "    interact_status = (\n",
    "        eval_df.groupby([DEFAULT_USER_COL])[DEFAULT_ITEM_COL].apply(set).reset_index()\n",
    "    )\n",
    "    total_interact = pd.DataFrame(\n",
    "        {DEFAULT_USER_COL: [], DEFAULT_ITEM_COL: [], DEFAULT_RATING_COL: []},\n",
    "        dtype=np.int32,\n",
    "    )\n",
    "    for index, user_items in interact_status.iterrows():\n",
    "        u = int(user_items[DEFAULT_USER_COL])\n",
    "        items = set(user_items[DEFAULT_ITEM_COL])  # item set for user u\n",
    "        n_items = len(items)  # number of positive item for user u\n",
    "        sample_neg_items = set(\n",
    "            item_sampler.sample(negative_num + n_items, 1, True)\n",
    "        )  # first sample negative_num+n_items items\n",
    "        sample_neg_items = list(sample_neg_items - items)[:negative_num]\n",
    "        # filter the positive items and truncate the first negative_num\n",
    "        #     print(len(sample_neg_items))\n",
    "        tp_items = np.append(list(items), sample_neg_items)\n",
    "        #     print(len(tp_items))\n",
    "\n",
    "        tp_users = np.ones(negative_num + n_items, dtype=np.int32) * u\n",
    "        tp_ones = np.ones(n_items, dtype=np.int32)\n",
    "        tp_zeros = np.zeros(negative_num, dtype=np.int32)\n",
    "        ratings = np.append(tp_ones, tp_zeros)\n",
    "        #     print(len(tp_users)),print(len(tp_items)),print(len(ratings))\n",
    "        tp = pd.DataFrame(\n",
    "            {\n",
    "                DEFAULT_USER_COL: tp_users,\n",
    "                DEFAULT_ITEM_COL: tp_items,\n",
    "                DEFAULT_RATING_COL: ratings,\n",
    "            }\n",
    "        )\n",
    "        total_interact = total_interact.append(tp)\n",
    "\n",
    "    total_interact = sklearn.utils.shuffle(total_interact)\n",
    "    return total_interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter items less than 10\n",
    "def fiter_by_count(tp, group_col, filter_col, num):\n",
    "    print(\"Filter\", group_col, \"by \", filter_col, \"less than\", num)\n",
    "    ordercount = (\n",
    "        tp.groupby([group_col])[filter_col].nunique().rename(\"count\").reset_index()\n",
    "    )\n",
    "    filter_tp = tp[\n",
    "        tp[group_col].isin(ordercount[ordercount[\"count\"] >= num][group_col])\n",
    "    ]\n",
    "    n_interact = len(filter_tp.index)\n",
    "    n_users = filter_tp[DEFAULT_USER_COL].nunique()\n",
    "    n_items = filter_tp[DEFAULT_ITEM_COL].nunique()\n",
    "    print(\"|\", n_users, \"|\", n_items, \"|\", n_interact, \"|\")\n",
    "    return filter_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_test_to_files(data, data_base_dir, suff_str=\"full\"):\n",
    "    user_ids = data[DEFAULT_USER_COL].to_numpy(dtype=np.int32)\n",
    "    item_ids = data[DEFAULT_ITEM_COL].to_numpy(dtype=np.int32)\n",
    "    ratings = data[DEFAULT_RATING_COL].to_numpy(dtype=np.float32)\n",
    "    file_path = data_base_dir + \"leave_one_out/\"\n",
    "    if not os.path.exists(file_path):\n",
    "        os.mkdir(file_path)\n",
    "    np.savez_compressed(\n",
    "        file_path + suff_str, user_ids=user_ids, item_ids=item_ids, ratings=ratings,\n",
    "    )\n",
    "    print(\n",
    "        \"Data saving to file:\",\n",
    "        data_base_dir,\n",
    "        \"max_item_num:\",\n",
    "        np.max(item_ids),\n",
    "        \"max_user_num:\",\n",
    "        np.max(user_ids),\n",
    "    )\n",
    "\n",
    "\n",
    "def save_train_to_files(data, data_base_dir, suff_str=\"\"):\n",
    "    user_ids = data[DEFAULT_USER_COL].to_numpy(dtype=np.int32)\n",
    "    item_ids = data[DEFAULT_ITEM_COL].to_numpy(dtype=np.int32)\n",
    "    timestamps = data[DEFAULT_TIMESTAMP_COL].to_numpy(dtype=np.int32)\n",
    "    ratings = data[DEFAULT_RATING_COL].to_numpy(dtype=np.float32)\n",
    "    file_path = data_base_dir + \"leave_one_out/\"\n",
    "    if not os.path.exists(file_path):\n",
    "        os.mkdir(file_path)\n",
    "    np.savez_compressed(\n",
    "        file_path + suff_str + \"train\",\n",
    "        user_ids=user_ids,\n",
    "        item_ids=item_ids,\n",
    "        timestamp=timestamps,\n",
    "        ratings=ratings,\n",
    "    )\n",
    "    print(\n",
    "        \"Data saving to file:\",\n",
    "        data_base_dir,\n",
    "        \"max_item_num:\",\n",
    "        np.max(item_ids),\n",
    "        \"max_user_num:\",\n",
    "        np.max(user_ids),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiter_full_data = fiter_by_count(data_df, DEFAULT_USER_COL, DEFAULT_ITEM_COL, 3)\n",
    "users = fiter_full_data[DEFAULT_USER_COL].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiter_full_data[DEFAULT_FLAG_COL] = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in users:\n",
    "    top_2_item_index = (\n",
    "        fiter_full_data[fiter_full_data[DEFAULT_USER_COL] == user]\n",
    "        .sort_values(by=[DEFAULT_TIMESTAMP_COL], ascending=False)\n",
    "        .head(2)\n",
    "        .index\n",
    "    )\n",
    "    fiter_full_data.loc[top_2_item_index[0], [DEFAULT_FLAG_COL]] = \"test\"\n",
    "    fiter_full_data.loc[top_2_item_index[1], [DEFAULT_FLAG_COL]] = \"validate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling negatives and saving\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "Filling unigram table\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "sampling negative items...\n",
      "sampling negative items...\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n",
      "Data saving to file: ../datasets/ml-1m/ max_item_num: 3952 max_user_num: 6040\n"
     ]
    }
   ],
   "source": [
    "print(\"sampling negatives and saving\")\n",
    "data_base_dir = \"../datasets/ml-1m/\"\n",
    "\n",
    "tp_train = fiter_full_data[fiter_full_data[DEFAULT_FLAG_COL] == \"train\"]\n",
    "tp_validate = fiter_full_data[fiter_full_data[DEFAULT_FLAG_COL] == \"validate\"]\n",
    "tp_test = fiter_full_data[fiter_full_data[DEFAULT_FLAG_COL] == \"test\"]\n",
    "\n",
    "save_train_to_files(tp_train, data_base_dir, suff_str=\"\")\n",
    "item_sampler = UnigramTable(tp_train[DEFAULT_ITEM_COL].value_counts().to_dict())\n",
    "for i in range(10):\n",
    "    tp_validate_new = feed_neg_sample(tp_validate, 100, item_sampler)\n",
    "    tp_test_new = feed_neg_sample(tp_test, 100, item_sampler)\n",
    "    save_test_to_files(tp_validate_new, data_base_dir, suff_str=\"valid\" + \"_\" + str(i))\n",
    "    save_test_to_files(tp_test_new, data_base_dir, suff_str=\"test\" + \"_\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
